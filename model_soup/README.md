### Model Soup
In order to further improve our performance, after training our cross-modal similarity model, we did the model ensemble according to the method proposed in ***Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time*** https://arxiv.org/abs/2203.05482. To conduct the model soup, you need to train our cross-modal under different settings like learning rate, frame sample rate, batch size etc. After that, you can obtain some checkpoint files which have the same model structure but different training settings, and then put these checkpoint files together, the model soup will automatically choose and do average with some checkpoint to boost the model's performance. 